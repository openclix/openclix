---
title: "Agent Case Evidence"
description: "Public evidence map for OpenClaw, Claude Code, and Codex retention-automation workflows."
---

Evidence snapshot date: **2026-02-27**.

This table is not a marketing claim list. It is an operations confidence reference for planning retention automation.

## Evidence table

| Tool | Case type | Reproducibility | KPI proof | Confidence | Notes |
| --- | --- | --- | --- | --- | --- |
| Claude Code | ASO workflow skill repo | High | Limited | B | Public repo with executable prompts/workflow, but limited public business KPI outcomes. |
| OpenClaw | App Store creative automation skill listing | Medium | Limited | B | Workflow artifacts are public; treat ecosystem plugins as supply-chain sensitive. |
| Codex | Product automation capability docs | Medium | Limited | B | Official product capability evidence exists; external mobile retention KPI case studies are sparse. |
| Cross-tool | Indie launch narratives | Low | Low | C | Useful directional context, not controlled KPI evidence. |

## Source links

- Claude Code ASO skill repo: [alirezarezvani/claude-code-aso-skill](https://github.com/alirezarezvani/claude-code-aso-skill)
- App Store data MCP server: [appreply-co/mcp-appstore](https://github.com/appreply-co/mcp-appstore)
- OpenClaw skill listing example: [app-store-screenshot-generation](https://playbooks.com/skills/openclaw/skills/app-store-screenshot-generation)
- Codex app announcement (automation support): [Introducing the Codex app](https://openai.com/index/introducing-the-codex-app/)
- Codex product page: [OpenAI Codex](https://openai.com/codex/)
- OpenClaw ecosystem security incident coverage: [The Verge report](https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare)

## How to use this in planning

- Treat `A/B/C` as decision confidence, not vendor ranking.
- Require local reproducibility before production rollout.
- Keep human approval gates for all config-apply operations.
